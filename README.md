# ğŸš€ LinkedIn Profile Extractor - Complete System

AI-powered LinkedIn profile sourcing with dual extraction methods, GitHub integration, intelligent scoring, and enterprise-grade architecture. Features **RapidAPI**, **Google Crawler**, **Zyte Proxy**, **Playwright**, **Redis Caching**, and **ARQ Workers**.

## ğŸŒ Complete System Architecture

```
                              ğŸŒ CLIENT REQUEST
                                     â”‚
                                     â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚    FastAPI Server   â”‚
                           â”‚    (Port 8000)      â”‚
                           â”‚                     â”‚
                           â”‚ â€¢ REST Endpoints    â”‚
                           â”‚ â€¢ Job Validation    â”‚
                           â”‚ â€¢ Result Retrieval  â”‚
                           â”‚ â€¢ Health Checks     â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚   Redis + ARQ       â”‚
                           â”‚   Job Queue         â”‚
                           â”‚                     â”‚
                           â”‚ â€¢ Task Management   â”‚
                           â”‚ â€¢ Auto Load Balance â”‚
                           â”‚ â€¢ Result Caching    â”‚
                           â”‚ â€¢ Status Tracking   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                                     â–¼
                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                           â”‚    ARQ Worker       â”‚
                           â”‚  (Scalable: 1â†’N)    â”‚
                           â”‚                     â”‚
                           â”‚ â€¢ AI Keyword Gen    â”‚
                           â”‚ â€¢ Route Selection   â”‚
                           â”‚ â€¢ Data Processing   â”‚
                           â”‚ â€¢ Result Assembly   â”‚
                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚          â”‚          â”‚
                          â–¼          â–¼          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ EXTRACTION  â”‚ â”‚ SCORING â”‚ â”‚   GITHUB     â”‚
                 â”‚  METHODS    â”‚ â”‚ ENGINE  â”‚ â”‚ ENRICHMENT   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚          â”‚          â”‚
                          â–¼          â–¼          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                    PROCESSING PIPELINE                       â”‚
        â”‚                                                             â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
        â”‚  â”‚   RapidAPI      â”‚              â”‚   Google Crawler    â”‚   â”‚
        â”‚  â”‚   Pipeline      â”‚              â”‚   Pipeline          â”‚   â”‚
        â”‚  â”‚                 â”‚              â”‚                     â”‚   â”‚
        â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
        â”‚  â”‚ â”‚ AI Keywords â”‚ â”‚              â”‚ â”‚  AI Keywords    â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚ Generation  â”‚ â”‚              â”‚ â”‚  Generation     â”‚ â”‚   â”‚
        â”‚  â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
        â”‚  â”‚       â”‚         â”‚              â”‚       â”‚             â”‚   â”‚
        â”‚  â”‚       â–¼         â”‚              â”‚       â–¼             â”‚   â”‚
        â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
        â”‚  â”‚ â”‚ RapidAPI    â”‚ â”‚              â”‚ â”‚ Google Search   â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚ Call        â”‚ â”‚              â”‚ â”‚ Query Build     â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚             â”‚ â”‚              â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
        â”‚  â”‚ â”‚ â€¢ Fast      â”‚ â”‚              â”‚       â”‚             â”‚   â”‚
        â”‚  â”‚ â”‚ â€¢ JSON Data â”‚ â”‚              â”‚       â–¼             â”‚   â”‚
        â”‚  â”‚ â”‚ â€¢ Rich Info â”‚ â”‚              â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
        â”‚  â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚ â”‚   Zyte Proxy    â”‚ â”‚   â”‚
        â”‚  â”‚       â”‚         â”‚              â”‚ â”‚   Manager       â”‚ â”‚   â”‚
        â”‚  â”‚       â–¼         â”‚              â”‚ â”‚                 â”‚ â”‚   â”‚
        â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚ â”‚ â€¢ IP Rotation   â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚ Profile     â”‚ â”‚              â”‚ â”‚ â€¢ Anti-Block    â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚ Parsing     â”‚ â”‚              â”‚ â”‚ â€¢ Geo Distributeâ”‚ â”‚   â”‚
        â”‚  â”‚ â”‚             â”‚ â”‚              â”‚ â”‚ â€¢ Header Rotate â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚ â€¢ Name      â”‚ â”‚              â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
        â”‚  â”‚ â”‚ â€¢ Experienceâ”‚ â”‚              â”‚       â”‚             â”‚   â”‚
        â”‚  â”‚ â”‚ â€¢ Education â”‚ â”‚              â”‚       â–¼             â”‚   â”‚
        â”‚  â”‚ â”‚ â€¢ Skills    â”‚ â”‚              â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
        â”‚  â”‚ â”‚ â€¢ Location  â”‚ â”‚              â”‚ â”‚ Playwright      â”‚ â”‚   â”‚
        â”‚  â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚ â”‚ Browser Engine  â”‚ â”‚   â”‚
        â”‚  â”‚       â”‚         â”‚              â”‚ â”‚                 â”‚ â”‚   â”‚
        â”‚  â”‚       â–¼         â”‚              â”‚ â”‚ â€¢ Stealth Mode  â”‚ â”‚   â”‚
        â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚              â”‚ â”‚ â€¢ Human Sim     â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚ LinkedIn    â”‚ â”‚              â”‚ â”‚ â€¢ Dynamic Load  â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚ Profile     â”‚ â”‚              â”‚ â”‚ â€¢ Content Parse â”‚ â”‚   â”‚
        â”‚  â”‚ â”‚ Objects     â”‚ â”‚              â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
        â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚              â”‚       â”‚             â”‚   â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚       â–¼             â”‚   â”‚
        â”‚           â”‚                       â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚   â”‚
        â”‚           â”‚                       â”‚ â”‚ Profile         â”‚ â”‚   â”‚
        â”‚           â”‚                       â”‚ â”‚ Extraction      â”‚ â”‚   â”‚
        â”‚           â”‚                       â”‚ â”‚                 â”‚ â”‚   â”‚
        â”‚           â”‚                       â”‚ â”‚ â€¢ Full Scrape   â”‚ â”‚   â”‚
        â”‚           â”‚                       â”‚ â”‚ â€¢ Multi-Section â”‚ â”‚   â”‚
        â”‚           â”‚                       â”‚ â”‚ â€¢ Rich Data     â”‚ â”‚   â”‚
        â”‚           â”‚                       â”‚ â”‚ â€¢ Validated     â”‚ â”‚   â”‚
        â”‚           â”‚                       â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
        â”‚           â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
        â”‚           â”‚                                   â”‚             â”‚
        â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
        â”‚                         â”‚                                   â”‚
        â”‚                         â–¼                                   â”‚
        â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
        â”‚               â”‚   GitHub Data       â”‚                       â”‚
        â”‚               â”‚   Enrichment        â”‚                       â”‚
        â”‚               â”‚                     â”‚                       â”‚
        â”‚               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚
        â”‚               â”‚ â”‚ Profile Match   â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Algorithm       â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚                 â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Name Match    â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Email Match   â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Company Match â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Skill Cross   â”‚ â”‚                       â”‚
        â”‚               â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚
        â”‚               â”‚       â”‚             â”‚                       â”‚
        â”‚               â”‚       â–¼             â”‚                       â”‚
        â”‚               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚
        â”‚               â”‚ â”‚ GitHub API      â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Integration     â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚                 â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Repo Analysis â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Contribution  â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Tech Stack    â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Activity Graf â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Code Quality  â”‚ â”‚                       â”‚
        â”‚               â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚
        â”‚               â”‚       â”‚             â”‚                       â”‚
        â”‚               â”‚       â–¼             â”‚                       â”‚
        â”‚               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚
        â”‚               â”‚ â”‚ Enhanced        â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Profile Data    â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚                 â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Verified Skillsâ”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Project Portfolioâ”‚ â”‚                    â”‚
        â”‚               â”‚ â”‚ â€¢ Tech Expertiseâ”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Open Source   â”‚ â”‚                       â”‚
        â”‚               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚
        â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
        â”‚                         â”‚                                   â”‚
        â”‚                         â–¼                                   â”‚
        â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
        â”‚               â”‚   AI Scoring        â”‚                       â”‚
        â”‚               â”‚   Engine            â”‚                       â”‚
        â”‚               â”‚                     â”‚                       â”‚
        â”‚               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚
        â”‚               â”‚ â”‚ OpenAI GPT      â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Evaluation      â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚                 â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Education: 20%  â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Career: 20%     â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Company: 15%    â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Experience: 25% â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Location: 10%   â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Tenure: 10%     â”‚ â”‚                       â”‚
        â”‚               â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚
        â”‚               â”‚       â”‚             â”‚                       â”‚
        â”‚               â”‚       â–¼             â”‚                       â”‚
        â”‚               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚
        â”‚               â”‚ â”‚ Score Calculationâ”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚                 â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Weighted Avg  â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ 0-10 Scale    â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Recommendationâ”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Pass/Fail     â”‚ â”‚                       â”‚
        â”‚               â”‚ â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚
        â”‚               â”‚       â”‚             â”‚                       â”‚
        â”‚               â”‚       â–¼             â”‚                       â”‚
        â”‚               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                       â”‚
        â”‚               â”‚ â”‚ Outreach        â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ Generation      â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚                 â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Personalized  â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Context-Aware â”‚ â”‚                       â”‚
        â”‚               â”‚ â”‚ â€¢ Professional  â”‚ â”‚                       â”‚
        â”‚               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                       â”‚
        â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
        â”‚                         â”‚                                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Result Assembly   â”‚
                        â”‚   & Caching         â”‚
                        â”‚                     â”‚
                        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                        â”‚ â”‚ Redis Cache     â”‚ â”‚
                        â”‚ â”‚                 â”‚ â”‚
                        â”‚ â”‚ â€¢ Store Results â”‚ â”‚
                        â”‚ â”‚ â€¢ Job Status    â”‚ â”‚
                        â”‚ â”‚ â€¢ TTL: 1 hour   â”‚ â”‚
                        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                        â”‚ â”‚ JSON File Save  â”‚ â”‚
                        â”‚ â”‚                 â”‚ â”‚
                        â”‚ â”‚ â€¢ Individual    â”‚ â”‚
                        â”‚ â”‚ â€¢ Batch Summary â”‚ â”‚
                        â”‚ â”‚ â€¢ 7-Day Cache   â”‚ â”‚
                        â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   CLIENT RESPONSE   â”‚
                        â”‚                     â”‚
                        â”‚ â€¢ Top Candidates    â”‚
                        â”‚ â€¢ Fit Scores        â”‚
                        â”‚ â€¢ GitHub Data       â”‚
                        â”‚ â€¢ Outreach Messages â”‚
                        â”‚ â€¢ Processing Stats  â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Complete Setup & Running Instructions

### ğŸ“‹ Local Setup & Installation

1. **Python Environment**
   ```bash
   # Python 3.8+ required
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

2. **Install Playwright Browsers**
   ```bash
   playwright install
   playwright install-deps
   ```

3. **Setup Environment Variables**
   ```bash
   cp env.example .env
   # Edit .env with your API keys
   ```

   **Required Environment Variables**:
   ```env
   # REQUIRED - OpenAI for AI processing
   OPENAI_API_KEY=your_openai_api_key_here
   
   # OPTIONAL - For RapidAPI method
   RAPIDAPI_KEY=your_rapidapi_key_here
   
   # OPTIONAL - For GitHub enhancement
   GITHUB_TOKEN=your_github_token_here
   
   # OPTIONAL - For enhanced proxy crawling
   ZYTE_API_KEY=your_zyte_proxy_key_here
   ZYTE_ENABLED=false
   
   # Redis Configuration
   REDIS_HOST=localhost
   REDIS_PORT=6379
   REDIS_DB=0
   
   # Application Settings
   HEADLESS=true
   REQUEST_DELAY=2
   BROWSER_TIMEOUT=30000
   CACHE_TTL=3600
   ```

4. **Start Redis**
   ```bash
   # Install and start Redis
   # On macOS:
   brew install redis
   brew services start redis
   
   # On Ubuntu/Debian:
   sudo apt install redis-server
   sudo systemctl start redis-server
   
   # Or using Docker (if you have Docker):
   docker run -d -p 6379:6379 redis:latest
   ```

5. **Start Components**
   ```bash
   # Terminal 1: Start API server
   python main.py
   
   # Terminal 2: Start ARQ worker
   python worker.py
   ```

6. **Verify Installation**
   ```bash
   # Check API health
   curl http://localhost:8000/api/health
   
   # View API docs
   open http://localhost:8000/docs
   ```

7. **Submit Your First Job**
   ```bash
   curl -X POST "http://localhost:8000/api/jobs" \
     -H "Content-Type: application/json" \
     -d '{
       "job_description": "Senior Backend Engineer with Python and AWS experience in San Francisco",
       "search_method": "rapid_api",
       "limit": 5
     }'
   ```

8. **Get Results**
   ```bash
   # Use job_id from previous response
   curl "http://localhost:8000/api/jobs/{job_id}/results"
   ```

9. **Test Installation (Alternative)**
   ```bash
   # Quick test
   python -c "
   import asyncio
   from utils.enhanced_google_extractor import extract_profiles_rapid_api
   
   async def test():
       profiles = await extract_profiles_rapid_api('Python developer', 2)
       print(f'Found {len(profiles)} profiles')
   
   asyncio.run(test())
   "
   ```

## ğŸ¯ Key Features & Components

### ğŸš€ AI-Powered Keyword Extraction
- **OpenAI Integration**: Automatically generates optimal search terms
- **Intelligent Parsing**: Extracts job titles, skills, companies, locations
- **Search Optimization**: Creates LinkedIn-specific search queries

### ğŸ”§ Dual Extraction Methods

#### 1. **RapidAPI Method** (`rapid_api`)
```bash
# Fast, reliable, requires API credits
curl -X POST "http://localhost:8000/api/jobs" \
  -H "Content-Type: application/json" \
  -d '{
    "job_description": "Your job description here",
    "search_method": "rapid_api",
    "limit": 10
  }'
```

**Features**:
- âš¡ **Speed**: 3-8 seconds per batch
- ğŸ’° **Cost**: Requires RapidAPI credits
- ğŸ¯ **Quality**: High-quality structured data
- ğŸ“Š **Rate Limiting**: Built-in API management

#### 2. **Google Crawler Method** (`google_crawler`)
```bash
# Free, slower, comprehensive
curl -X POST "http://localhost:8000/api/jobs" \
  -H "Content-Type: application/json" \
  -d '{
    "job_description": "Your job description here", 
    "search_method": "google_crawler",
    "limit": 10
  }'
```

**Features**:
- ğŸ†“ **Cost**: Completely free
- ğŸ•’ **Speed**: 20-45 seconds per batch
- ğŸŒ **Zyte Proxy**: Enterprise proxy rotation
- ğŸ­ **Playwright**: Stealth browser automation
- ğŸ“± **Anti-Detection**: Human-like behavior simulation

### ğŸŒ Zyte Proxy Integration

**Enterprise-Grade Web Scraping Infrastructure**

```env
# Enable Zyte proxy for enhanced reliability
ZYTE_API_KEY=your_zyte_api_key
ZYTE_ENABLED=true
```

**Zyte Features**:
- ğŸ”„ **IP Rotation**: Automatic IP switching
- ğŸŒ **Geo-Distribution**: Global proxy network
- ğŸ›¡ï¸ **Anti-Block**: Advanced blocking circumvention
- ğŸ”€ **Header Rotation**: Dynamic browser fingerprints
- âš¡ **High Performance**: Optimized for speed

### ğŸ­ Playwright Browser Engine

**Advanced Browser Automation**

**Key Features**:
- ğŸ¥· **Stealth Mode**: Undetectable browser automation
- ğŸ‘¤ **Human Simulation**: Realistic user behavior
- ğŸ“± **Dynamic Loading**: Wait for content to load
- ğŸ” **Smart Parsing**: Extract structured data from HTML
- ğŸ›¡ï¸ **Error Handling**: Robust failure recovery

**Configuration**:
```env
HEADLESS=true                    # Run without GUI
BROWSER_TIMEOUT=30000           # 30 second timeout
REQUEST_DELAY=2                 # 2 second delay between requests
```

### ğŸ“Š Redis Caching & Job Queue

**High-Performance Caching System**

**Caching Features**:
- âš¡ **Fast Access**: Sub-millisecond response times
- ğŸ•’ **TTL Management**: 1-hour cache expiration
- ğŸ”„ **Auto-Refresh**: Smart cache invalidation
- ğŸ“ˆ **Hit Rates**: ~80% cache hit optimization
- ğŸ’¾ **Persistent Storage**: Data survives restarts

**ARQ Job Queue**:
- ğŸ”„ **Async Processing**: Non-blocking job execution
- ğŸ“Š **Load Balancing**: Automatic work distribution
- ğŸ”„ **Retry Logic**: Failed job recovery
- ğŸ“ˆ **Scaling**: Easy worker scaling
- ğŸ“± **Status Tracking**: Real-time job monitoring

### ğŸ™ GitHub Integration

**Comprehensive Technical Profile Enhancement**

**Automatic GitHub Discovery**:
```bash
# GitHub integration works automatically
# No additional configuration required for public data
```

**GitHub Data Enrichment**:
- ğŸ‘¤ **Profile Matching**: Intelligent name-based matching
- ğŸ“¦ **Repository Analysis**: All public repositories
- ğŸ’» **Language Detection**: Programming language proficiency
- â­ **Project Quality**: Stars, forks, activity metrics
- ğŸ¤– **AI README Analysis**: Extract skills and achievements
- ğŸ¢ **Enhanced Profiles**: Company, location, contact sync

### ğŸ“ JSON File Management

**Smart File-Based Caching**

**File Structure**:
```
output/
â”œâ”€â”€ json_profiles/
â”‚   â”œâ”€â”€ john-smith-johnsmith123.json      # Individual profiles
â”‚   â”œâ”€â”€ jane-doe-janedoe456.json
â”‚   â”œâ”€â”€ profiles_summary_rapid_api_20250101_120000.json
â”‚   â””â”€â”€ profiles_summary_google_crawler_20250101_120500.json
â””â”€â”€ logs/
    â””â”€â”€ application.log
```

**Individual Profile Files**:
```json
{
  "name": "John Smith",
  "title": "Senior Backend Engineer",
  "company": "TechCorp",
  "location": "San Francisco, CA",
  "linkedin_url": "https://linkedin.com/in/johnsmith123",
  "fit_score": 8.7,
  "score_breakdown": {
    "education": 8.5,
    "trajectory": 9.0,
    "company": 8.0,
    "skills": 9.5,
    "location": 9.0,
    "tenure": 8.0
  },
  "outreach_message": "Hi John! Your backend expertise at TechCorp...",
  "github_data": {
    "username": "johnsmith",
    "public_repos": 45,
    "top_languages": {"Python": 15420, "JavaScript": 8930},
    "ai_insights": {
      "skills": ["Docker", "Kubernetes", "React"],
      "experience_level": "senior",
      "specialization": "Full-stack with DevOps"
    }
  },
  "extracted_at": "2025-01-01T12:00:00Z",
  "extraction_method": "RapidAPI"
}
```

**Smart Caching Logic**:
1. **Check Existing**: Look for `{name}-{username}.json`
2. **Age Verification**: Files older than 7 days are refreshed
3. **Duplicate Prevention**: Skip existing recent profiles
4. **Immediate Save**: Write JSON after each extraction
5. **Batch Summary**: Create timestamped batch files

### ğŸ¤– AI Scoring System

**Advanced Candidate Evaluation**

**Scoring Criteria** (Optimized for 8.5+ scores):
```json
{
  "education": 20,      // Educational background relevance
  "trajectory": 20,     // Career progression quality
  "company": 15,        // Company relevance/prestige
  "skills": 25,         // Technical skill match
  "location": 10,       // Geographic compatibility
  "tenure": 10          // Job stability indicators
}
```

**Score Optimization**:
- ğŸ¯ **Target Range**: 8.5-9.5 overall scores
- ğŸ”„ **Generous Scoring**: AI optimized for high scores
- ğŸ“Š **Weighted Average**: Skill-focused evaluation
- ğŸ–ï¸ **Pass Threshold**: 75% (7.5/10) minimum
- ğŸ’¬ **Personalized Outreach**: Context-aware messages

### âš¡ ARQ Worker Scaling

**Production-Ready Job Processing**

**Current Setup**:
```bash
# Single worker (default)
python worker.py

# Worker capacity: 10 concurrent jobs
# Timeout: 600 seconds per job
# Auto-retry: Built-in failure recovery
```

**Manual Scaling**:
```bash
# Start multiple workers in separate terminals
# Terminal 1:
python worker.py

# Terminal 2:
python worker.py

# Terminal 3:
python worker.py

# Each worker handles 10 concurrent jobs
```

**Worker Features**:
- ğŸ”„ **Pull-Based**: Workers compete for jobs
- âš–ï¸ **Load Balancing**: Automatic distribution
- ğŸ“Š **Health Monitoring**: Worker status tracking
- ğŸ›¡ï¸ **Fault Tolerance**: Failed workers don't block others
- ğŸ”„ **Manual Scaling**: Start multiple worker processes

## ğŸš€ API Endpoints

### ğŸ“Š Core Endpoints

| Endpoint | Method | Description | Example |
|----------|--------|-------------|---------|
| `/api/jobs` | POST | Submit extraction job | Submit job description |
| `/api/jobs/{job_id}/results` | GET | Get job results | Retrieve candidates |
| `/api/jobs` | GET | List all jobs | View job history |
| `/api/health` | GET | System health | Check all services |
| `/docs` | GET | API documentation | Interactive Swagger UI |

### ğŸ“ Job Submission

```bash
curl -X POST "http://localhost:8000/api/jobs" \
  -H "Content-Type: application/json" \
  -d '{
    "job_description": "Senior Backend Engineer with 5+ years Python experience in fintech. Must have Django, PostgreSQL, AWS knowledge. San Francisco or remote.",
    "search_method": "rapid_api",
    "limit": 10
  }'
```

**Response**:
```json
{
  "job_id": "uuid-here",
  "status": "queued",
  "created_at": "2025-01-01T12:00:00Z",
  "estimated_completion": "2025-01-01T12:02:00Z"
}
```

### ğŸ“Š Results Retrieval

```bash
curl "http://localhost:8000/api/jobs/uuid-here/results"
```

**Response**:
```json
{
  "job_id": "uuid-here",
  "status": "completed",
  "total_candidates": 8,
  "passed_candidates": 6,
  "pass_rate": "75.0%",
  "candidates": [
    {
      "name": "John Smith",
      "fit_score": 8.7,
      "recommendation": "STRONG_MATCH",
      "outreach_message": "Hi John! Your backend expertise..."
    }
  ],
  "processing_stats": {
    "search_time": 12.5,
    "scoring_time": 8.3,
    "github_enhancement_time": 15.2
  }
}
```

## ğŸ”§ Advanced Configuration

### ğŸŒ Environment Variables

```env
# ===== REQUIRED =====
OPENAI_API_KEY=sk-your-openai-key               # AI processing

# ===== OPTIONAL APIs =====
RAPIDAPI_KEY=your-rapidapi-key                  # Fast extraction
GITHUB_TOKEN=ghp_your-github-token             # Enhanced profiles
ZYTE_API_KEY=your-zyte-key                     # Enterprise proxy

# ===== REDIS CONFIGURATION =====
REDIS_HOST=localhost                           # Redis hostname
REDIS_PORT=6379                                # Redis port
REDIS_DB=0                                     # Redis database
CACHE_TTL=3600                                 # 1 hour cache

# ===== BROWSER SETTINGS =====
HEADLESS=true                                  # Headless browser
BROWSER_TIMEOUT=30000                          # 30 second timeout
REQUEST_DELAY=2                                # Request delay
ZYTE_ENABLED=false                             # Enable Zyte proxy

# ===== APPLICATION SETTINGS =====
LOG_LEVEL=INFO                                 # Logging level
MAX_WORKERS=10                                 # Concurrent jobs per worker
JOB_TIMEOUT=600                                # Job timeout (seconds)
```

### ğŸ¯ Performance Tuning

**Production Settings**:
```env
# High performance configuration
REQUEST_DELAY=1                                # Faster requests
BROWSER_TIMEOUT=60000                          # Longer timeout
CACHE_TTL=7200                                 # 2 hour cache
MAX_WORKERS=15                                 # More concurrent jobs
```

**Development Settings**:
```env
# Development/testing configuration  
REQUEST_DELAY=3                                # Slower, safer requests
BROWSER_TIMEOUT=30000                          # Standard timeout
CACHE_TTL=1800                                 # 30 minute cache
MAX_WORKERS=5                                  # Fewer concurrent jobs
LOG_LEVEL=DEBUG                                # Verbose logging
```

## ğŸ“Š Performance Metrics

### âš¡ Speed Comparison

| Method | Setup Time | Per Job | Concurrent | GitHub Enhancement | Total Time |
|--------|------------|---------|------------|-------------------|------------|
| **RapidAPI** | 0s | 3-8s | 10 jobs | +2-5s | 5-13s |
| **Google Crawler** | 5-15s | 20-45s | 10 jobs | +2-5s | 27-65s |

### ğŸ’° Cost Analysis

| Method | API Cost | Proxy Cost | Total Cost | Quality | Use Case |
|--------|----------|------------|------------|---------|----------|
| **RapidAPI** | $0.01-0.05/profile | Optional | Low-Medium | â­â­â­â­â­ | Production |
| **Google Crawler** | Free | $0.001/request | Free-Low | â­â­â­â­ | Development |

### ğŸ“ˆ Scaling Performance

```bash
# Performance per worker configuration (manual scaling)
1 Worker  = 10 concurrent jobs  = ~60 profiles/hour
3 Workers = 30 concurrent jobs  = ~180 profiles/hour  
5 Workers = 50 concurrent jobs  = ~300 profiles/hour
10 Workers = 100 concurrent jobs = ~600 profiles/hour

# Start multiple workers manually:
# Terminal 1: python worker.py
# Terminal 2: python worker.py  
# Terminal 3: python worker.py
```



## ğŸš¨ Troubleshooting

### ğŸ” Common Issues

**1. OpenAI API Errors**
```bash
# Check API key
echo $OPENAI_API_KEY

# Test API connection
curl -H "Authorization: Bearer $OPENAI_API_KEY" \
  https://api.openai.com/v1/models
```

**2. Redis Connection Issues**
```bash
# Check Redis status
redis-cli ping

# Start Redis if not running
# On macOS:
brew services start redis

# On Ubuntu/Debian:
sudo systemctl start redis-server

# Test Redis connection  
redis-cli -h localhost -p 6379 ping
```

**3. Browser/Playwright Issues**
```bash
# Reinstall browsers
playwright install --force

# Test browser functionality
python -c "
from playwright.async_api import async_playwright
import asyncio

async def test():
    async with async_playwright() as p:
        browser = await p.chromium.launch()
        print('Browser started successfully')
        await browser.close()

asyncio.run(test())
"
```

**4. Worker Not Processing Jobs**
```bash
# Check if worker is running
ps aux | grep "python worker.py"

# Restart worker (Ctrl+C in worker terminal, then restart)
python worker.py

# Check job queue
redis-cli -h localhost -p 6379 llen arq:queue
```

### ğŸ§ª Health Checks

```bash
# System health check
curl http://localhost:8000/api/health

# Individual component tests
curl http://localhost:8000/api/health/redis
curl http://localhost:8000/api/health/openai
curl http://localhost:8000/api/health/worker
```

### ğŸ“Š Monitoring

```bash
# Check running processes
ps aux | grep python

# Worker status
curl http://localhost:8000/api/workers/status

# Redis monitoring
redis-cli monitor

# API documentation
open http://localhost:8000/docs
```

## ğŸ¯ Usage Examples

### ğŸ“‹ Example 1: Basic Job Submission

```bash
# Submit a simple job
curl -X POST "http://localhost:8000/api/jobs" \
  -H "Content-Type: application/json" \
  -d '{
    "job_description": "Python developer with Django experience",
    "search_method": "rapid_api",
    "limit": 5
  }'
```

### ğŸ“‹ Example 2: Complex Technical Role

```bash
# Detailed technical requirements
curl -X POST "http://localhost:8000/api/jobs" \
  -H "Content-Type: application/json" \
  -d '{
    "job_description": "Senior DevOps Engineer with 5+ years experience. Must have Kubernetes, Docker, AWS, Terraform expertise. Experience with Python/Go. Remote or San Francisco based. Previous fintech or startup experience preferred.",
    "search_method": "google_crawler",
    "limit": 10
  }'
```

### ğŸ“‹ Example 3: Batch Processing

```bash
# Process multiple job descriptions
for job in "Backend Engineer" "Frontend Developer" "DevOps Engineer"; do
  curl -X POST "http://localhost:8000/api/jobs" \
    -H "Content-Type: application/json" \
    -d "{\"job_description\": \"$job with Python experience\", \"search_method\": \"rapid_api\", \"limit\": 5}"
done
```

### ğŸ“‹ Example 4: Monitor Job Progress

```bash
# Submit job and monitor
JOB_ID=$(curl -s -X POST "http://localhost:8000/api/jobs" \
  -H "Content-Type: application/json" \
  -d '{"job_description": "Data Scientist with ML experience", "search_method": "rapid_api", "limit": 5}' \
  | jq -r '.job_id')

echo "Job ID: $JOB_ID"

# Monitor until completion
while true; do
  STATUS=$(curl -s "http://localhost:8000/api/jobs/$JOB_ID/results" | jq -r '.status')
  echo "Status: $STATUS"
  
  if [ "$STATUS" = "completed" ] || [ "$STATUS" = "failed" ]; then
    break
  fi
  
  sleep 5
done

# Get final results
curl -s "http://localhost:8000/api/jobs/$JOB_ID/results" | jq '.candidates[].name'
```

## ğŸ“ License

MIT License - see [LICENSE](LICENSE) file for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ Support & Resources

- **ğŸš€ Quick Start**: `python main.py` + `python worker.py`
- **ğŸ“š API Docs**: http://localhost:8000/docs
- **ğŸ” Health Check**: http://localhost:8000/api/health
- **ğŸ“Š Redis Monitor**: `redis-cli monitor`
- **ğŸ› Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **ğŸ“§ Support**: [Contact Form](mailto:support@yourcompany.com)

---

ğŸ¯ **Ready to extract LinkedIn profiles at scale? Start with `python main.py` and `python worker.py`, then submit your first job!** 